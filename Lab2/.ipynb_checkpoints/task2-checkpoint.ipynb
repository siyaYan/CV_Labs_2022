{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c4ce1377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "test=np.load('data/kmnist-npz/kmnist-train-imgs.npz')['arr_0']\n",
    "print(test[1,:,:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9d3fa63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "\n",
    "torch.manual_seed(17)\n",
    "\n",
    "# train_imgs_file = 'data/kmnist-npz/kmnist-train-imgs.npz'\n",
    "# train_labels_file = 'data/kmnist-npz/kmnist-train-labels.npz'\n",
    "batchsize = 5\n",
    "epochs = 3\n",
    "lr = 0.001\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "#   output[channel] = (input[channel] - mean[channel]) / std[channel]\n",
    "#   output range(-1,1)<<-- input(0.5(mean),0.5(std))\n",
    "#   (inputmin(0)-0,5)/0.5=-1 \n",
    "#   (inputmax(1)-0.5)/0.5=1\n",
    "    transforms.Normalize([0.5],[0.5]),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(28,padding=4),\n",
    "    \n",
    "    \n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5],[0.5])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5],[0.5])\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d074eaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "import pandas as pd\n",
    "class MyDataset(data.Dataset):\n",
    "    def __init__(self,imgs,labels, transform=None, target_transform=None):\n",
    "        self.imgs = np.load(imgs)['arr_0']\n",
    "        self.labels=np.load(labels)['arr_0']\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.imgs[idx,:,:]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ca0e0cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = MyDataset(\n",
    "    imgs='data/kmnist-npz/kmnist-train-imgs.npz',\n",
    "    labels='data/kmnist-npz/kmnist-train-labels.npz',\n",
    "    transform=train_transforms,\n",
    "    target_transform=None\n",
    "\n",
    ")\n",
    "testing_set = MyDataset(\n",
    "    imgs='data/kmnist-npz/kmnist-test-imgs.npz',\n",
    "    labels='data/kmnist-npz/kmnist-test-labels.npz',\n",
    "    transform=test_transforms,\n",
    "    target_transform=None,\n",
    ")\n",
    "valing_set = MyDataset(\n",
    "    imgs='data/kmnist-npz/kmnist-val-imgs.npz',\n",
    "    labels='data/kmnist-npz/kmnist-val-labels.npz',\n",
    "    transform=val_transforms,\n",
    "    target_transform=None\n",
    ")\n",
    "\n",
    "trainloader = data.DataLoader(training_set, batch_size=batchsize, shuffle=True)\n",
    "testloader = data.DataLoader(testing_set, batch_size=batchsize, shuffle=True)\n",
    "valloader = data.DataLoader(valing_set, batch_size=batchsize, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb91fc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# convolutional layer(change channels' num)\n",
    "# H(output)=(H(input)−F+2P)/S+1\n",
    "# pooling layer(change image size, usually 1/2)\n",
    "# H(output)=(H(input)−F)/S+1\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "#      28*28*1 -> 28*28*32\n",
    "        self.conv1 = nn.Conv2d(1,32,5,stride=1,padding=2)\n",
    "#     28*28*32 ->14*14*32\n",
    "#     14*14*32 ->14*14*64\n",
    "        self.conv2 = nn.Conv2d(32,64,3,stride=1,padding=1)\n",
    "#         7*7*64\n",
    "        self.fc1 = nn.Linear(7*7*64, 1024)\n",
    "        self.fc2 = nn.Linear(1024 , 10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "#         first relu & pooling\n",
    "        res1 = F.relu(self.conv1(x))\n",
    "        res2 = F.max_pool2d(res1,2)\n",
    "        \n",
    "#         second relu & pooling\n",
    "        res3 = F.relu(self.conv2(res2))\n",
    "        res4 = F.max_pool2d(res3,2)\n",
    "\n",
    "#         third connect & relu & connect\n",
    "        res4 = res4.view(res4.shape[0], -1)\n",
    "        res5 = self.fc1(res4)\n",
    "        res6 = F.relu(res5)\n",
    "        output = self.fc2(res6)\n",
    "        \n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c575c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(epochs,trainloader,valloader):\n",
    "    train_losses=[]\n",
    "    train_accs=[]\n",
    "    val_accs=[]\n",
    "    CNN = Model()\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(CNN.parameters(), lr=1e-3, betas=(0.9,0.999))\n",
    "    running_loss=0.0\n",
    "    train_acc=0.0\n",
    "    val_acc=0.0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss=0.0\n",
    "        accuracy=0.0\n",
    "        train_acc=0.0\n",
    "        val_acc=0.0\n",
    "        total=0.0\n",
    "        train_loss=0.0\n",
    "        for i ,data in enumerate(trainloader,0):\n",
    "            inputs,labels = data\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = CNN(inputs)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss +=loss.item()\n",
    "            train_loss += running_loss\n",
    "            accuracy += (outputs.argmax(dim=1) == labels).sum().item()\n",
    "            train_acc += accuracy\n",
    "            total+=labels.size(0)\n",
    "#             writer.add_scalar(\"acc vs epoch\", trainAccSum/n, epoch)\n",
    "            if i%2000==1999:\n",
    "#                 writer.add_scalar(\"acc vs epoch\", trainAccSum/n, epoch)\n",
    "#                 print(f'running_loss:{running_loss}, acc:{trainAccSum/n}')\n",
    "                print(running_loss)\n",
    "                print(f'[{epoch +1},{i+1:5d}], acc:{accuracy/2000}% ,loss:{running_loss/2000:.3f}')\n",
    "                running_loss=0.0\n",
    "                accuracy=0.0\n",
    "        \n",
    "        PATH = './checkpoints/cifar_net_{:02d}.pth'.format(epoch)\n",
    "        torch.save(CNN.state_dict(),PATH)\n",
    "        \n",
    "#         writer.add_scalar(\"acc vs epoch\", train_acc/len(trainloader), epoch)\n",
    "        train_accs.append(train_acc/len(trainloader))\n",
    "        print('training acc of epoch{:2d}:{:0f}'.format(epoch+1,100.*train_acc/len(trainloader) ))\n",
    "        train_losses.append(train_loss/len(trainloader))\n",
    "        \n",
    "        validation_loss = 0.0\n",
    "        running_loss = 0.0\n",
    "        print('starting validation for epoch {}'.format(epoch+1))\n",
    "        with torch.no_grad():\n",
    "            for data in valloader:\n",
    "                inputs,labels = data\n",
    "            \n",
    "#               optimizer.zero_grad()\n",
    "                outputs = CNN(inputs)\n",
    "                loss = loss_func(outputs, labels)\n",
    "#                 optimizer.step()\n",
    "                validation_loss+=loss.item()\n",
    "                val_acc += (outputs.argmax(dim=1) == labels).sum().item()\n",
    "                total+=labels.size(0) \n",
    "        \n",
    "            validation_loss/=len(valloader)\n",
    "            val_accs.append(val_acc/total)\n",
    "            print('validation loss for epoch{:2d}:{:5f}'.format(epoch+1,validation_loss))\n",
    "            print('validation acc for epoch{:2d}:{:0f}'.format(epoch+1,100.*val_acc/total))\n",
    "            \n",
    "    print('finished training')\n",
    "    return train_accs,train_losses,val_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "57273840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(testloader):\n",
    "    CNN = Model()\n",
    "    CNN.load_state_dict(torch.load('./checkpoints/cifar_net_03.pth'))\n",
    "    \n",
    "    correct=0.0\n",
    "    total =0 \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images,labels = data\n",
    "            outputs = CNN(images)\n",
    "            correct += (outputs.argmax(dim=1) == labels).sum().item()\n",
    "#             _,predicted=torch.max(outputs,data,1)\n",
    "            total+=labels.size(0) \n",
    "#             correct+=(predicted==labels).sum().item()\n",
    "\n",
    "    print(f'accuracy of the cnn on the testing images is :{100.*correct/total:.0f}')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "104343fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "def display(train_accs,train_losses,val_accs):\n",
    "    for i,train_accs in enumerate(train_accs,0):\n",
    "        \n",
    "        writer.add_scalar(\"train_acc vs epoch\", train_accs, i+1)\n",
    "        writer.add_scalar(\"train_loss vs epoch\", train_losses[i], i+1)    \n",
    "        writer.add_scalar(\"validation_acc vs epoch\", val_accs[i], i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951eb7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2000], acc:2.7505% ,loss:1.289\n",
      "[1, 4000], acc:3.8455% ,loss:0.704\n",
      "[1, 6000], acc:4.1535% ,loss:0.529\n",
      "[1, 8000], acc:4.2975% ,loss:0.441\n",
      "[1,10000], acc:4.388% ,loss:0.383\n",
      "training acc of epoch 1:381864.593220\n",
      "starting validation for epoch 1\n",
      "validation loss for epoch 1:0.274874\n",
      "validation acc for epoch 1:1.536667\n",
      "[2, 2000], acc:4.4855% ,loss:0.324\n",
      "[2, 4000], acc:4.499% ,loss:0.319\n",
      "[2, 6000], acc:4.54% ,loss:0.298\n",
      "[2, 8000], acc:4.5825% ,loss:0.267\n",
      "[2,10000], acc:4.5755% ,loss:0.275\n"
     ]
    }
   ],
   "source": [
    "train_accs,train_losses,val_accs=training(epochs,trainloader,valloader)\n",
    "display(train_accs,train_losses,val_accs)\n",
    "# testing(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "eb5a6e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf95af43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
